{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "598741c3-4ffa-4a76-a71f-fd454b7792fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a simple encoder for LiDAR and Wireless data\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.fc(x), dim=-1)  # Normalize embeddings\n",
    "\n",
    "# Contrastive loss function (InfoNCE)\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z_lidar, z_wireless):\n",
    "        # Compute similarity scores\n",
    "        batch_size = z_lidar.shape[0]\n",
    "        similarity_matrix = torch.matmul(z_lidar, z_wireless.T) / self.temperature\n",
    "        \n",
    "        # Labels: Positive pairs are along the diagonal\n",
    "        labels = torch.arange(batch_size).to(z_lidar.device)\n",
    "\n",
    "        # Contrastive loss (cross entropy)\n",
    "        loss = F.cross_entropy(similarity_matrix, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ff538c-8678-4d97-8de0-3053a8deecd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 3.9146\n",
      "Epoch [2/10], Loss: 4.1143\n",
      "Epoch [3/10], Loss: 3.8663\n",
      "Epoch [4/10], Loss: 4.0039\n",
      "Epoch [5/10], Loss: 3.8992\n",
      "Epoch [6/10], Loss: 3.6615\n",
      "Epoch [7/10], Loss: 3.8361\n",
      "Epoch [8/10], Loss: 3.6478\n",
      "Epoch [9/10], Loss: 3.7248\n",
      "Epoch [10/10], Loss: 3.6406\n"
     ]
    }
   ],
   "source": [
    "# Dummy dataset (random values for demonstration)\n",
    "batch_size = 32\n",
    "input_dim_lidar = 256  # Example LiDAR feature size\n",
    "input_dim_wireless = 64  # Example Wireless feature size\n",
    "embedding_dim = 128  # Common feature space\n",
    "\n",
    "# Create model encoders\n",
    "lidar_encoder = Encoder(input_dim_lidar, embedding_dim)\n",
    "wireless_encoder = Encoder(input_dim_wireless, embedding_dim)\n",
    "contrastive_loss = ContrastiveLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(list(lidar_encoder.parameters()) + list(wireless_encoder.parameters()), lr=0.001)\n",
    "lidar_mean = 1.0\n",
    "wireless_mean = -1.0\n",
    "\n",
    "# Simulated training loop\n",
    "for epoch in range(10):\n",
    "    # Generate random LiDAR and wireless signal batches\n",
    "    lidar_data = lidar_mean + torch.randn(batch_size, input_dim_lidar)\n",
    "    wireless_data = wireless_mean + torch.randn(batch_size, input_dim_wireless)\n",
    "\n",
    "    # Forward pass\n",
    "    z_lidar = lidar_encoder(lidar_data)\n",
    "    z_wireless = wireless_encoder(wireless_data)\n",
    "\n",
    "    # Compute contrastive loss\n",
    "    loss = contrastive_loss(z_lidar, z_wireless)\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe570f1-4f0d-4842-8437-85751ed5ed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Wireless Embedding: tensor([[-1.3338e-02, -1.4952e-01, -1.1626e-01,  1.3133e-02, -7.8757e-02,\n",
      "         -2.3399e-01,  5.8289e-02, -3.2043e-02,  2.0553e-02,  3.6751e-02,\n",
      "         -8.9260e-02, -2.3509e-01, -1.0999e-01, -1.2852e-01,  4.5394e-02,\n",
      "         -5.1564e-03,  8.9713e-02,  1.8391e-02, -3.3704e-02, -6.5114e-02,\n",
      "         -6.2521e-02, -1.2830e-01,  1.1763e-01, -5.1911e-03, -6.5447e-02,\n",
      "          1.1717e-01,  9.6474e-02, -9.2325e-02,  8.6627e-02, -1.3535e-01,\n",
      "         -4.6381e-02, -1.1306e-01, -1.2122e-01, -1.2439e-01,  6.5801e-04,\n",
      "          9.5302e-02,  6.9749e-02,  2.1700e-02, -3.8526e-02, -7.6341e-02,\n",
      "         -3.5308e-02, -1.2578e-01,  1.7543e-01,  2.2614e-02,  1.1007e-01,\n",
      "          1.0313e-01,  1.5084e-01,  8.5247e-02, -4.3069e-03, -1.1093e-01,\n",
      "          3.0664e-02,  3.8549e-03, -1.3603e-02, -4.6426e-02,  2.6469e-03,\n",
      "         -3.7562e-02, -1.6371e-02,  6.2779e-02, -1.6141e-01,  6.5662e-02,\n",
      "         -3.2636e-02, -1.2427e-01, -7.8374e-03, -5.8346e-04,  3.4853e-03,\n",
      "          8.3652e-02,  7.4893e-02, -3.6680e-02,  1.1743e-01, -1.1753e-02,\n",
      "         -4.7700e-02,  7.7261e-02,  6.8769e-05, -1.1780e-01,  1.8406e-01,\n",
      "          4.0388e-02,  1.1716e-02,  2.0690e-02,  7.1793e-02, -1.4011e-01,\n",
      "          4.9012e-02, -1.4757e-01,  7.2820e-03,  1.9887e-02,  8.4668e-02,\n",
      "          2.1434e-03,  2.7638e-02,  6.8525e-02,  4.8423e-02, -7.6440e-02,\n",
      "         -8.6277e-02, -1.2119e-01,  1.7909e-01, -1.8850e-02, -1.4203e-02,\n",
      "         -5.8090e-02, -2.5416e-02,  4.7825e-02,  6.9755e-02, -3.0826e-02,\n",
      "         -1.1955e-01, -1.2657e-01, -1.1265e-01,  2.0607e-01,  1.1279e-02,\n",
      "         -8.0071e-02, -2.3666e-01,  8.7909e-02,  3.2939e-02,  1.7736e-02,\n",
      "          1.1916e-01, -3.2711e-02, -2.7066e-02, -3.1857e-03, -2.3991e-02,\n",
      "         -1.1094e-01, -1.5919e-02, -3.5227e-02,  2.2266e-02, -9.3603e-02,\n",
      "          1.9758e-02, -1.4585e-01,  3.3034e-03,  2.2911e-02, -5.2308e-02,\n",
      "         -5.1971e-02, -8.8033e-02, -3.8818e-02]])\n"
     ]
    }
   ],
   "source": [
    "def predict_wireless_from_lidar(lidar_sample):\n",
    "    with torch.no_grad():\n",
    "        z_lidar = lidar_encoder(lidar_sample.unsqueeze(0))  # Get embedding\n",
    "        return z_lidar  # Can be used for nearest-neighbor retrieval\n",
    "\n",
    "# Example inference with new LiDAR scan\n",
    "lidar_sample = torch.randn(input_dim_lidar)  # Simulated new LiDAR input\n",
    "predicted_embedding = predict_wireless_from_lidar(lidar_sample)\n",
    "print(\"Predicted Wireless Embedding:\", predicted_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae1ff25-8aab-4dc7-bbb2-5ac179873ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
